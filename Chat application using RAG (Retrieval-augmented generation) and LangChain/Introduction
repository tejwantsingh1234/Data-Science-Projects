# Building a Chat application using RAG (Retrieval-augmented generation) and LangChain

### Importance of RAG and how it is better than fine-tuning the LLM or building it from scratch

1. Fine-tuning is much more expensive as it requires trillions and trillions of data to train the LLM and also takes a lot of time.
2. Fine-tuning needs custom serving and maintenance.
3. Fine-tuning doesn't give you the auto-update feature.

### RAG Workflow:

1. **Retrieve**: Extract relevant information from a knowledge base or documents.
2. **Generate**: Use an LLM to generate human-like responses based on the retrieved information.

### Key Components of this Project:

1. **Knowledge Base/Vector Store** - To store the relevant documents in a searchable format (vector embeddings).
2. **LLM (Language Model)** - For generating intelligent and context-related answers.
3. **LangChain** - Acts as the glue to connect components (retriever, LLM, database).
4. **Frontend** - Using Streamlit
